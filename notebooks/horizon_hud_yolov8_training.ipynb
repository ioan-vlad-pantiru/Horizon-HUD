{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Horizon-HUD: YOLOv8n Safety Detection Training\n",
        "\n",
        "**Setup:**\n",
        "1. Upload BDD100K images as a Kaggle dataset (e.g. `bdd100k-images`) with `train/` and `val/` folders\n",
        "2. Upload BDD100K labels as a Kaggle dataset (e.g. `bdd100k-labels`) with `train/` and `val/` folders\n",
        "3. Add both as inputs to this notebook (right sidebar > Add Data)\n",
        "4. Set Accelerator to **GPU P100** or **T4 x2** in Settings\n",
        "5. Enable **Internet** in Settings\n",
        "6. Update the paths in Cell 2 below\n",
        "\n",
        "**Resume after timeout:** See Cell 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-19T15:21:20.832881Z",
          "iopub.status.busy": "2026-02-19T15:21:20.832534Z",
          "iopub.status.idle": "2026-02-19T15:21:24.891567Z",
          "shell.execute_reply": "2026-02-19T15:21:24.890460Z",
          "shell.execute_reply.started": "2026-02-19T15:21:20.832853Z"
        },
        "trusted": true
      },
      "source": [
        "!pip install -q ultralytics"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-19T15:21:24.894334Z",
          "iopub.status.busy": "2026-02-19T15:21:24.893917Z",
          "iopub.status.idle": "2026-02-19T15:21:24.905335Z",
          "shell.execute_reply": "2026-02-19T15:21:24.904485Z",
          "shell.execute_reply.started": "2026-02-19T15:21:24.894300Z"
        },
        "trusted": true
      },
      "source": [
        "# ============================================================\n",
        "# CONFIGURATION\n",
        "# ============================================================\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Show available datasets (top 3 levels only, no deep scan)\n",
        "print(\"Available inputs:\")\n",
        "base = Path(\"/kaggle/input\")\n",
        "for d1 in sorted(base.iterdir()):\n",
        "    print(f\"  {d1}/\")\n",
        "    if d1.is_dir():\n",
        "        for d2 in sorted(d1.iterdir()):\n",
        "            print(f\"    {d2.name}/\")\n",
        "            if d2.is_dir():\n",
        "                for d3 in sorted(d2.iterdir()):\n",
        "                    if d3.is_dir():\n",
        "                        print(f\"      {d3.name}/  -> {sorted(os.listdir(d3))[:5]}\")\n",
        "print()\n",
        "\n",
        "# ---- SET THESE TO MATCH THE OUTPUT ABOVE ----\n",
        "IMAGES_ROOT = \"/kaggle/input/datasets/ioanvladpantiru/100k-labels/100k/100k\"\n",
        "LABELS_ROOT = \"/kaggle/input/datasets/ioanvladpantiru/100k-labels/100k_labels/100k_labels\"\n",
        "\n",
        "# Resume: to continue training after a timeout:\n",
        "# 1. Download last.pt from previous run output\n",
        "# 2. Upload it as a new Kaggle dataset (e.g. \"horizon-checkpoint\")\n",
        "# 3. Add it as input and set the path here:\n",
        "RESUME_FROM = None  # e.g. \"/kaggle/input/horizon-checkpoint/last.pt\"\n",
        "\n",
        "# ============================================================\n",
        "# ADVANCED (usually no need to change)\n",
        "# ============================================================\n",
        "EPOCHS = 100\n",
        "IMGSZ = 640\n",
        "BATCH = -1       # -1 = auto-detect best batch size for your GPU\n",
        "WORKERS = 2"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Available inputs:\n",
            "  /kaggle/input/datasets/\n",
            "    ioanvladpantiru/\n",
            "      100k-labels/  -> ['100k', '100k_labels']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-19T15:21:24.906794Z",
          "iopub.status.busy": "2026-02-19T15:21:24.906522Z",
          "iopub.status.idle": "2026-02-19T15:21:27.588494Z",
          "shell.execute_reply": "2026-02-19T15:21:27.587614Z",
          "shell.execute_reply.started": "2026-02-19T15:21:24.906761Z"
        },
        "trusted": true
      },
      "source": [
        "# ============================================================\n",
        "# PREFLIGHT CHECKS\n",
        "# ============================================================\n",
        "import os, shutil, json, torch\n",
        "from pathlib import Path\n",
        "\n",
        "WORK = Path(\"/kaggle/working\")\n",
        "DATASET = WORK / \"dataset\"\n",
        "MODELS = WORK / \"models\"\n",
        "DOWNLOAD = WORK / \"download\"\n",
        "\n",
        "errors = []\n",
        "\n",
        "# GPU\n",
        "if torch.cuda.is_available():\n",
        "    gpu = torch.cuda.get_device_name(0)\n",
        "    vram = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "    print(f\"GPU: {gpu} ({vram:.1f} GB)\")\n",
        "else:\n",
        "    errors.append(\"No GPU detected. Go to Settings > Accelerator and select GPU.\")\n",
        "\n",
        "# Disk\n",
        "disk = shutil.disk_usage(str(WORK))\n",
        "free_gb = disk.free / 1e9\n",
        "print(f\"Disk free: {free_gb:.1f} GB\")\n",
        "if free_gb < 5:\n",
        "    errors.append(f\"Low disk space: {free_gb:.1f} GB free, need at least 5 GB.\")\n",
        "\n",
        "# Inputs\n",
        "if not RESUME_FROM:\n",
        "    for name, root in [(\"Images\", IMAGES_ROOT), (\"Labels\", LABELS_ROOT)]:\n",
        "        r = Path(root)\n",
        "        if not r.exists():\n",
        "            errors.append(f\"{name} root not found: {r}  -- Check the dataset name in Add Data.\")\n",
        "            continue\n",
        "        for split in [\"train\", \"val\"]:\n",
        "            d = r / split\n",
        "            if not d.exists():\n",
        "                errors.append(f\"{name} missing {split}/ subfolder in {r}\")\n",
        "else:\n",
        "    p = Path(RESUME_FROM)\n",
        "    if not p.exists():\n",
        "        errors.append(f\"Resume checkpoint not found: {p}\")\n",
        "\n",
        "if errors:\n",
        "    print(\"\\n=== ERRORS ===\")\n",
        "    for e in errors:\n",
        "        print(f\"  - {e}\")\n",
        "    raise RuntimeError(\"Fix the errors above before continuing.\")\n",
        "\n",
        "if not RESUME_FROM:\n",
        "    imgs_root = Path(IMAGES_ROOT)\n",
        "    lbls_root = Path(LABELS_ROOT)\n",
        "    n_train_img = len(list((imgs_root / \"train\").glob(\"*.jpg\")))\n",
        "    n_val_img = len(list((imgs_root / \"val\").glob(\"*.jpg\")))\n",
        "    n_train_lbl = len(list((lbls_root / \"train\").glob(\"*.json\")))\n",
        "    n_val_lbl = len(list((lbls_root / \"val\").glob(\"*.json\")))\n",
        "    print(f\"Train: {n_train_img} images, {n_train_lbl} label files\")\n",
        "    print(f\"Val:   {n_val_img} images, {n_val_lbl} label files\")\n",
        "    if n_train_img == 0:\n",
        "        raise RuntimeError(\"No training images found. Check that your images dataset has train/*.jpg\")\n",
        "else:\n",
        "    print(f\"Resuming from: {RESUME_FROM}\")\n",
        "\n",
        "print(\"\\nAll checks passed.\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU: Tesla P100-PCIE-16GB (17.1 GB)\n",
            "Disk free: 20.9 GB\n",
            "Train: 70000 images, 70000 label files\n",
            "Val:   10000 images, 10000 label files\n",
            "\n",
            "All checks passed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-19T15:21:27.590023Z",
          "iopub.status.busy": "2026-02-19T15:21:27.589738Z",
          "iopub.status.idle": "2026-02-19T15:23:41.119880Z",
          "shell.execute_reply": "2026-02-19T15:23:41.119016Z",
          "shell.execute_reply.started": "2026-02-19T15:21:27.589998Z"
        },
        "trusted": true
      },
      "source": [
        "# ============================================================\n",
        "# PREPARE YOLO DATASET (skipped on resume)\n",
        "# ============================================================\n",
        "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
        "\n",
        "BDD_TO_HORIZON = {\n",
        "    \"car\": 0, \"bus\": 0, \"truck\": 0, \"train\": 0,\n",
        "    \"person\": 1,\n",
        "    \"rider\": 2, \"bike\": 2, \"motor\": 2, \"motorcycle\": 2, \"bicycle\": 2,\n",
        "    \"traffic sign\": 3, \"traffic light\": 3,\n",
        "}\n",
        "IMG_W, IMG_H = 1280, 720\n",
        "\n",
        "def convert_one(args):\n",
        "    label_path, out_dir = args\n",
        "    try:\n",
        "        with open(label_path) as f:\n",
        "            ann = json.load(f)\n",
        "    except Exception:\n",
        "        return -1\n",
        "    frames = ann.get(\"frames\", [])\n",
        "    if not frames:\n",
        "        Path(out_dir / (label_path.stem + \".txt\")).write_text(\"\")\n",
        "        return 0\n",
        "    lines = []\n",
        "    for obj in frames[0].get(\"objects\", []):\n",
        "        cls_id = BDD_TO_HORIZON.get(obj.get(\"category\", \"\").lower())\n",
        "        if cls_id is None:\n",
        "            continue\n",
        "        box = obj.get(\"box2d\", {})\n",
        "        if not box:\n",
        "            continue\n",
        "        x1 = max(0.0, float(box.get(\"x1\", 0)))\n",
        "        y1 = max(0.0, float(box.get(\"y1\", 0)))\n",
        "        x2 = min(float(IMG_W), float(box.get(\"x2\", 0)))\n",
        "        y2 = min(float(IMG_H), float(box.get(\"y2\", 0)))\n",
        "        if x2 <= x1 or y2 <= y1:\n",
        "            continue\n",
        "        cx = ((x1 + x2) / 2.0) / IMG_W\n",
        "        cy = ((y1 + y2) / 2.0) / IMG_H\n",
        "        w = (x2 - x1) / IMG_W\n",
        "        h = (y2 - y1) / IMG_H\n",
        "        lines.append(f\"{cls_id} {cx:.6f} {cy:.6f} {w:.6f} {h:.6f}\")\n",
        "    Path(out_dir / (label_path.stem + \".txt\")).write_text(\n",
        "        \"\\n\".join(lines) + (\"\\n\" if lines else \"\")\n",
        "    )\n",
        "    return len(lines)\n",
        "\n",
        "if RESUME_FROM:\n",
        "    print(\"Skipping dataset prep (resuming).\")\n",
        "else:\n",
        "    imgs_root = Path(IMAGES_ROOT)\n",
        "    lbls_root = Path(LABELS_ROOT)\n",
        "    total_objects = 0\n",
        "    total_errors = 0\n",
        "\n",
        "    for split in [\"train\", \"val\"]:\n",
        "        img_dst = DATASET / \"images\" / split\n",
        "        lbl_dst = DATASET / \"labels\" / split\n",
        "        img_dst.mkdir(parents=True, exist_ok=True)\n",
        "        lbl_dst.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Symlink each image file (keeps /images/ in the path for YOLO)\n",
        "        src_dir = imgs_root / split\n",
        "        existing = set(os.listdir(img_dst))\n",
        "        jpgs = sorted(src_dir.glob(\"*.jpg\"))\n",
        "        linked = 0\n",
        "        for jpg in jpgs:\n",
        "            if jpg.name not in existing:\n",
        "                os.symlink(str(jpg), str(img_dst / jpg.name))\n",
        "                linked += 1\n",
        "        print(f\"{split}: linked {linked} images (skipped {len(existing)} existing)\")\n",
        "\n",
        "        # Convert labels\n",
        "        json_files = sorted((lbls_root / split).glob(\"*.json\"))\n",
        "        print(f\"{split}: converting {len(json_files)} labels...\")\n",
        "        work = [(p, lbl_dst) for p in json_files]\n",
        "        with ProcessPoolExecutor(max_workers=4) as pool:\n",
        "            futures = {pool.submit(convert_one, w): w for w in work}\n",
        "            for fut in as_completed(futures):\n",
        "                n = fut.result()\n",
        "                if n < 0:\n",
        "                    total_errors += 1\n",
        "                else:\n",
        "                    total_objects += n\n",
        "\n",
        "    print(f\"\\nConverted: {total_objects} objects\")\n",
        "    if total_errors > 0:\n",
        "        print(f\"Warning: {total_errors} label files failed to parse (skipped)\")\n",
        "\n",
        "    # Verify\n",
        "    n_img = len(list((DATASET / \"images/train\").glob(\"*.jpg\")))\n",
        "    n_lbl = len(list((DATASET / \"labels/train\").glob(\"*.txt\")))\n",
        "    print(f\"Verification: {n_img} train images, {n_lbl} train labels\")\n",
        "    if n_lbl == 0:\n",
        "        raise RuntimeError(\"No labels were created. Check your labels dataset structure.\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train: linked 70000 images (skipped 0 existing)\n",
            "train: converting 70000 labels...\n",
            "val: linked 10000 images (skipped 0 existing)\n",
            "val: converting 10000 labels...\n",
            "\n",
            "Converted: 1473536 objects\n",
            "Verification: 70000 train images, 70000 train labels\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-19T15:23:41.122637Z",
          "iopub.status.busy": "2026-02-19T15:23:41.122048Z",
          "iopub.status.idle": "2026-02-19T15:23:41.129166Z",
          "shell.execute_reply": "2026-02-19T15:23:41.128033Z",
          "shell.execute_reply.started": "2026-02-19T15:23:41.122605Z"
        },
        "trusted": true
      },
      "source": [
        "# ============================================================\n",
        "# DATASET YAML (always recreated so resume works even if /working was cleared)\n",
        "# ============================================================\n",
        "dataset_yaml = DATASET / \"dataset.yaml\"\n",
        "\n",
        "if not RESUME_FROM:\n",
        "    dataset_yaml.parent.mkdir(parents=True, exist_ok=True)\n",
        "    dataset_yaml.write_text(f\"\"\"path: {DATASET}\n",
        "train: images/train\n",
        "val: images/val\n",
        "\n",
        "nc: 4\n",
        "names:\n",
        "  0: vehicle\n",
        "  1: pedestrian\n",
        "  2: cyclist\n",
        "  3: road_obstacle\n",
        "\"\"\")\n",
        "    print(f\"Created: {dataset_yaml}\")\n",
        "else:\n",
        "    print(\"Dataset yaml not needed for resume (config is inside last.pt)\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Created: /kaggle/working/dataset/dataset.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-19T15:23:41.130967Z",
          "iopub.status.busy": "2026-02-19T15:23:41.130561Z"
        },
        "trusted": true
      },
      "source": [
        "# ============================================================\n",
        "# TRAIN\n",
        "# ============================================================\n",
        "from ultralytics import YOLO\n",
        "\n",
        "train_ok = False\n",
        "try:\n",
        "    if RESUME_FROM:\n",
        "        print(f\"Resuming from {RESUME_FROM}\")\n",
        "        model = YOLO(RESUME_FROM)\n",
        "        model.train(resume=True)\n",
        "    else:\n",
        "        model = YOLO(\"yolov8s.pt\")\n",
        "        model.train(\n",
        "            data=str(dataset_yaml),\n",
        "            epochs=EPOCHS,\n",
        "            imgsz=IMGSZ,\n",
        "            batch=BATCH,\n",
        "            device=0,\n",
        "            project=str(MODELS),\n",
        "            name=\"horizon_v1\",\n",
        "            exist_ok=True,\n",
        "\n",
        "            # Safety-critical: maximize recall\n",
        "            conf=0.001,\n",
        "            iou=0.6,\n",
        "\n",
        "            # Augmentation for road scenes\n",
        "            hsv_h=0.015,\n",
        "            hsv_s=0.7,\n",
        "            hsv_v=0.4,\n",
        "            degrees=0.0,\n",
        "            translate=0.1,\n",
        "            scale=0.5,\n",
        "            fliplr=0.5,\n",
        "            flipud=0.0,\n",
        "            mosaic=1.0,\n",
        "            mixup=0.1,\n",
        "\n",
        "            # Training\n",
        "            optimizer=\"AdamW\",\n",
        "            lr0=0.001,\n",
        "            lrf=0.01,\n",
        "            warmup_epochs=3,\n",
        "            weight_decay=0.0005,\n",
        "            patience=20,\n",
        "            save=True,\n",
        "            save_period=5,\n",
        "            val=True,\n",
        "            plots=True,\n",
        "            verbose=True,\n",
        "            workers=WORKERS,\n",
        "            time=20,\n",
        "        )\n",
        "    train_ok = True\n",
        "    print(\"\\nTraining completed successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"\\nTraining stopped: {e}\")\n",
        "    print(\"Attempting to save whatever checkpoint exists...\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ‚úÖ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolov8n.pt to 'yolov8n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 6.2MB 69.2MB/s 0.1s\n",
            "Ultralytics 8.4.14 üöÄ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=-1, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=0.001, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/dataset/dataset.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, end2end=None, epochs=100, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.6, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.1, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=horizon_v1, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/models, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/models/horizon_v1, save_frames=False, save_json=False, save_period=5, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 755.1KB 30.2MB/s 0.0s\n",
            "Overriding model.yaml nc=80 with nc=4\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    752092  ultralytics.nn.modules.head.Detect           [4, 16, None, [64, 128, 256]] \n",
            "Model summary: 130 layers, 3,011,628 parameters, 3,011,612 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26n.pt to 'yolo26n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5.3MB 107.2MB/s 0.0s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.6¬±0.1 ms, read: 9.7¬±3.4 MB/s, size: 55.7 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/labels/train... 70000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 70000/70000 490.2it/s 2:23<0.0s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dataset/images/train/75055858-7d04a650.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/dataset/labels/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=640 at 60.0% CUDA memory utilization.\n",
            "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (Tesla P100-PCIE-16GB) 15.89G total, 0.10G reserved, 0.06G allocated, 15.73G free\n",
            "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
            "     3011628       8.197         0.419          48.7           nan        (1, 3, 640, 640)                    list\n",
            "     3011628       16.39         0.818          27.1           nan        (2, 3, 640, 640)                    list\n",
            "     3011628       32.79         1.367         25.04           nan        (4, 3, 640, 640)                    list\n",
            "     3011628       65.58         2.600         30.27           nan        (8, 3, 640, 640)                    list\n",
            "     3011628       131.2         5.035         44.81           nan       (16, 3, 640, 640)                    list\n",
            "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 28 for CUDA:0 8.86G/15.89G (56%) ‚úÖ\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 100.7¬±23.8 MB/s, size: 60.5 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/dataset/labels/train.cache... 70000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 70000/70000 14.0Git/s 0.0s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/dataset/images/train/75055858-7d04a650.jpg: 1 duplicate labels removed\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.5¬±0.3 ms, read: 8.7¬±3.6 MB/s, size: 64.9 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/dataset/labels/val... 10000 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 10000/10000 469.7it/s 21.3s.1s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/dataset/labels/val.cache\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0004375), 63 bias(decay=0.0)\n",
            "Plotting labels to /kaggle/working/models/horizon_v1/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/kaggle/working/models/horizon_v1\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      1/100      5.71G      1.781      1.538      1.117       1105        640: 18% ‚îÅ‚îÅ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 446/2500 2.6it/s 2:58<13:19"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true
      },
      "source": [
        "# ============================================================\n",
        "# SAVE OUTPUTS (runs even if training was interrupted)\n",
        "# ============================================================\n",
        "DOWNLOAD.mkdir(exist_ok=True)\n",
        "\n",
        "weights_dir = MODELS / \"horizon_v1\" / \"weights\"\n",
        "if not weights_dir.exists():\n",
        "    # Check default ultralytics save location\n",
        "    alt = Path(\"/kaggle/working/runs/detect/horizon_v1/weights\")\n",
        "    if alt.exists():\n",
        "        weights_dir = alt\n",
        "\n",
        "saved = []\n",
        "if weights_dir.exists():\n",
        "    for name in [\"best.pt\", \"last.pt\"]:\n",
        "        src = weights_dir / name\n",
        "        if src.exists():\n",
        "            shutil.copy(src, DOWNLOAD / name)\n",
        "            size_mb = src.stat().st_size / 1e6\n",
        "            saved.append(f\"{name} ({size_mb:.1f} MB)\")\n",
        "else:\n",
        "    print(\"No weights directory found.\")\n",
        "\n",
        "# Training plots\n",
        "results_dir = weights_dir.parent if weights_dir.exists() else None\n",
        "if results_dir and results_dir.exists():\n",
        "    for f in results_dir.glob(\"*.png\"):\n",
        "        shutil.copy(f, DOWNLOAD / f.name)\n",
        "        saved.append(f.name)\n",
        "    for f in results_dir.glob(\"*.csv\"):\n",
        "        shutil.copy(f, DOWNLOAD / f.name)\n",
        "        saved.append(f.name)\n",
        "\n",
        "print(f\"Saved to {DOWNLOAD}:\")\n",
        "for s in saved:\n",
        "    print(f\"  {s}\")\n",
        "\n",
        "if not saved:\n",
        "    print(\"Nothing saved - training may not have produced any checkpoints.\")\n",
        "elif \"last.pt\" in [s.split()[0] for s in saved]:\n",
        "    print(\"\\nTo resume: upload last.pt as a Kaggle dataset and set RESUME_FROM in Cell 2.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true
      },
      "source": [
        "# ============================================================\n",
        "# EXPORT TO TFLITE (only if training completed)\n",
        "# ============================================================\n",
        "best_path = DOWNLOAD / \"best.pt\"\n",
        "if best_path.exists():\n",
        "    try:\n",
        "        best = YOLO(str(best_path))\n",
        "        best.export(format=\"tflite\", imgsz=320, int8=True)\n",
        "        # Find the exported file and copy to download\n",
        "        for f in Path(\".\").rglob(\"*_saved_model/*.tflite\"):\n",
        "            shutil.copy(f, DOWNLOAD / \"horizon_v1_int8.tflite\")\n",
        "            print(f\"TFLite exported: {DOWNLOAD / 'horizon_v1_int8.tflite'}\")\n",
        "            break\n",
        "        else:\n",
        "            for f in Path(\".\").rglob(\"*.tflite\"):\n",
        "                shutil.copy(f, DOWNLOAD / f.name)\n",
        "                print(f\"TFLite exported: {DOWNLOAD / f.name}\")\n",
        "                break\n",
        "    except Exception as e:\n",
        "        print(f\"TFLite export failed: {e}\")\n",
        "        print(\"You can export locally: yolo export model=best.pt format=tflite imgsz=320 int8\")\n",
        "else:\n",
        "    print(\"No best.pt found, skipping export.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true
      },
      "source": [
        "# ============================================================\n",
        "# QUICK VISUAL TEST (only if best.pt exists)\n",
        "# ============================================================\n",
        "if best_path.exists():\n",
        "    import glob\n",
        "    val_dir = DATASET / \"images\" / \"val\"\n",
        "    if not val_dir.exists():\n",
        "        val_dir = Path(IMAGES_ROOT) / \"val\"\n",
        "    test_imgs = sorted(glob.glob(str(val_dir / \"*.jpg\")))[:5]\n",
        "    if test_imgs:\n",
        "        best = YOLO(str(best_path))\n",
        "        results = best.predict(\n",
        "            source=test_imgs, conf=0.25, iou=0.6, imgsz=640,\n",
        "            save=True, project=str(DOWNLOAD), name=\"test_predictions\", exist_ok=True\n",
        "        )\n",
        "        for r in results:\n",
        "            n = len(r.boxes) if r.boxes is not None else 0\n",
        "            print(f\"{Path(r.path).name}: {n} detections\")\n",
        "    else:\n",
        "        print(\"No val images found for testing.\")\n",
        "else:\n",
        "    print(\"No best.pt, skipping test.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true
      },
      "source": [
        "# ============================================================\n",
        "# FINAL SUMMARY\n",
        "# ============================================================\n",
        "print(\"=\" * 50)\n",
        "print(\"DOWNLOAD FILES:\")\n",
        "if DOWNLOAD.exists():\n",
        "    for f in sorted(DOWNLOAD.rglob(\"*\")):\n",
        "        if f.is_file():\n",
        "            size = f.stat().st_size / 1e6\n",
        "            print(f\"  {f.relative_to(DOWNLOAD)}  ({size:.1f} MB)\")\n",
        "print(\"=\" * 50)\n",
        "if (DOWNLOAD / \"last.pt\").exists() and not train_ok:\n",
        "    print(\"\\nTraining was interrupted!\")\n",
        "    print(\"To resume:\")\n",
        "    print(\"  1. Download last.pt from this notebook's output\")\n",
        "    print(\"  2. Create a new Kaggle dataset from it\")\n",
        "    print(\"  3. Set RESUME_FROM in Cell 2 to the path\")\n",
        "    print(\"  4. Run all cells again\")\n",
        "elif train_ok:\n",
        "    print(\"\\nTraining completed! Download best.pt and the .tflite for your Pi5.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "databundleVersionId": 15689039,
          "datasetId": 9485432,
          "sourceId": 14831116,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 31287,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}